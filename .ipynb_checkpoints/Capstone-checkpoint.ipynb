{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    "\n",
    "Text classification is the process of assigning tags or categories to text according to its content. It’s one of the fundamental tasks in natural language processing. \n",
    "\n",
    "The text we wanna classify is given as input to an algorithm, the algorithm will then analyze the text’s content, and then categorize the input as one of the tags or categories previously given.\n",
    "\n",
    "**Input → Classifying Algorithm → Classification of Input**\n",
    "\n",
    "Real life examples: \n",
    "\n",
    "+ sentiment analysis: how does the writer of the sentence feel about what they are writing about, do they think positively or negatively of the subject?\n",
    "Ex. restaurant reviews\n",
    "topic labeling: given sentences and a set of topics, which topic does this sentence fall under? \n",
    "Ex. is this essay about history? Math? etc?\n",
    "spam detection\n",
    "Ex. Email filtering: is this email a real important email or spam?\n",
    "\n",
    "Example. \n",
    "A restaurant wants to evaluate their ratings but don’t want to read through all of them. Therefore, they wanna use a computer algorithm to do all their work. They simply want to know if the customer’s review is positive or negative.\n",
    "\n",
    "Here’s an example of a customer’s review and a simple way an algorithm could classify their review.\n",
    "\n",
    "Input: “The food here was too salty and too expensive” \n",
    "\n",
    "Algorithm: \n",
    "Goes through every word in the sentence and counts how many positive words and how many negative words are in the sentence.\n",
    "\n",
    "\t\t“The, food, here, was, too, and” are all neutral words\n",
    "\n",
    "\t\t“Salty, expensive” are negative words.\n",
    "\n",
    "\t\tNegative words: 2\n",
    "\t\tPositive words: 0\n",
    "\n",
    "Classification: Negative Review, because there are more negative words (2) than positive (0).\n",
    "\n",
    "However, this algorithm obviously doesn’t work in a lot of cases. \n",
    "\n",
    "For example, “The food here was good, not expensive and not salty” would be classified as negative but it’s actually a positive review. \n",
    "\n",
    "Language and text can get very complicated which makes creating these algorithms difficult. Some things that make language difficult could be words that have multiple meanings, negation words (words such as not), slang, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import string\n",
    "from scipy import sparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingFile = \"trainingSet.txt\"\n",
    "testingFile = \"testSet.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(fileName):\n",
    "    f = open(fileName)\n",
    "    file = f.readlines()\n",
    "\n",
    "    sentences = []\n",
    "    sentiments = []\n",
    "\n",
    "    for line in file:\n",
    "        sentence, sentiment = line.split('\\t')\n",
    "        sentences.append(sentence.strip())\n",
    "        sentiments.append(int(sentiment.strip())) # Sentiment in {0,1}\n",
    "\n",
    "    return sentences, np.array(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSentences, trainingLabels = getData(trainingFile)\n",
    "testingSentences, testingLabels = getData(testingFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(sentences):\n",
    "    # The various sources of stop words\n",
    "    pronouns = {\"i\", \"me\", \"us\", \"you\", \"she\", \"her\", \"he\", \"him\", \"it\", \"we\", \"us\", \"they\", \"them\", \"this\", \"these\"}\n",
    "    # Source: https://en.wikipedia.org/wiki/English_personal_pronouns\n",
    "    copulae = {\"be\", \"is\", \"am\", \"are\", \"being\", \"was\", \"were\", \"been\"}\n",
    "    # Source: https://en.wikipedia.org/wiki/Copula_(linguistics)#English\n",
    "    conjunctions = {\"for\", \"and\", \"nor\", \"but\", \"or\", \"yet\", \"so\", \"that\", \"which\", \"because\", \"as\", \"since\", \"though\", \"while\", \"whereas\"}\n",
    "    # Source: https://en.wikipedia.org/wiki/Conjunction_(grammar)\n",
    "\n",
    "    stopwords = {\"a\", \"the\"}.union(pronouns).union(copulae).union(conjunctions)\n",
    "\n",
    "    def cleanText(text):\n",
    "        # Make lower case\n",
    "        text = text.lower()\n",
    "\n",
    "        # Replace non-text characters with spaces\n",
    "        nonText = string.punctuation + (\"\")\n",
    "        text = text.translate(string.maketrans(nonText, ' ' * (len(nonText))))\n",
    "\n",
    "        # Tokenize\n",
    "        words = text.split()\n",
    "\n",
    "        return words\n",
    "\n",
    "    return list(map(cleanText, sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'deleteDigits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b8498b967da2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainingTokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingSentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtestingTokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestingSentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-e882dd240cd4>\u001b[0m in \u001b[0;36mpreProcess\u001b[0;34m(sentences)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleanText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-e882dd240cd4>\u001b[0m in \u001b[0;36mcleanText\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Replace non-text characters with spaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mnonText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigits\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdeleteDigits\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonText\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'deleteDigits' is not defined"
     ]
    }
   ],
   "source": [
    "trainingTokens = preProcess(trainingSentences)\n",
    "testingTokens = preProcess(testingSentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVocab(sentences):\n",
    "    vocab = set()\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            vocab.add(word)\n",
    "    return sorted(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'absolute', 'absolutely', 'accomodate', 'across', 'actually', 'added', 'after', 'afternoon', 'again', 'ago', 'ahead', 'airport', 'albondigas', 'all', 'allergy', 'almonds', 'almost', 'alone', 'also', 'although', 'always', 'am', 'amazing', 'ambiance', 'ambience', 'amount', 'an', 'and', 'angry', 'another', 'anticipated', 'any', 'anything', 'anytime', 'anyway', 'apologize', 'app', 'appalling', 'appetizers', 'apple', 'approval', 'are', 'area', 'aren', 'aria', 'around', 'arrives', 'arriving', 'as', 'ask', 'asked', 'at', 'ate', 'atmosphere', 'atrocious', 'attack', 'attention', 'attentive', 'attitudes', 'auju', 'authentic', 'average', 'avocado', 'avoid', 'avoided', 'away', 'awesome', 'awful', 'awkward', 'az', 'baba', 'baby', 'back', 'bacon', 'bad', 'bagels', 'bakery', 'baklava', 'bamboo', 'bank', 'bar', 'barely', 'bargain', 'bartender', 'based', 'basically', 'batch', 'bathroom', 'bathrooms', 'bay', 'be', 'bean', 'beans', 'beat', 'beateous', 'beautifully', 'beauty', 'because', 'become', 'beef', 'been', 'beer', 'before', 'being', 'believe', 'bellagio', 'below', 'best', 'better', 'between', 'big', 'bigger', 'biggest', 'bill', 'bird', 'biscuit', 'biscuits', 'bisque', 'bit', 'bitches', 'bites', 'black', 'blah', 'blame', 'bland', 'blandest', 'blanket', 'block', 'bloddy', 'bloodiest', 'blown', 'blows', 'blue', 'boba', 'bodes', 'boiled', 'bone', 'boot', 'boring', 'both', 'bother', 'bottom', 'box', 'boy', 'boyfriend', 'boys', 'bread', 'break', 'breakfast', 'breaks', 'brick', 'bring', 'brother', 'brought', 'brownish', 'brunch', 'bruschetta', 'bucks', 'buffet', 'bug', 'building', 'buldogis', 'burger', 'burgers', 'burned', 'burrittos', 'bus', 'business', 'businesses', 'busy', 'but', 'butter', 'by', 'cafe', 'caf\\xc3\\xa9', 'cake', 'calamari', 'came', 'camelback', 'can', 'cannoli', 'cannot', 'cant', 'cape', 'capers', 'car', 'care', 'carly', 'cartel', 'cashew', 'cashier', 'caterpillar', 'cause', 'chains', 'changing', 'char', 'charcoal', 'charge', 'cheap', 'cheated', 'check', 'checked', 'cheese', 'chef', 'chefs', 'chicken', 'chip', 'chipotle', 'chips', 'christmas', 'claimed', 'class', 'classics', 'clean', 'climbing', 'close', 'clue', 'cocktail', 'cocktails', 'cod', 'coffee', 'cold', 'college', 'color', 'combination', 'come', 'comfortable', 'coming', 'companions', 'company', 'complain', 'completely', 'con', 'concept', 'connisseur', 'consider', 'considering', 'consistent', 'constructed', 'contain', 'contained', 'cook', 'cooked', 'cooking', 'cool', 'corn', 'correct', 'cost', 'could', 'count', 'couple', 'couples', 'coupons', 'course', 'courteous', 'cover', 'covered', 'cow', 'coziness', 'crab', 'cranberry', 'cream', 'creamy', 'crema', 'crepe', 'crisp', 'crispy', 'croutons', 'crust', 'crusty', 'crystals', 'cr\\xc3\\xaape', 'cuisine', 'curry', 'customer', 'customers', 'customize', 'cut', 'cute', 'd', 'damn', 'dark', 'dates', 'day', 'dead', 'deal', 'decided', 'decision', 'decor', 'decorated', 'dedicated', 'deeply', 'definitely', 'del', 'delicate', 'delicious', 'deliciously', 'delight', 'delish', 'deliver', 'denny', 'describing', 'despite', 'dessert', 'desserts', 'devine', 'did', 'didn', 'die', 'different', 'dine', 'dining', 'dinner', 'dirty', 'disappointed', 'disappointing', 'disappointment', 'disapppointment', 'disbelief', 'disgrace', 'disgusted', 'dish', 'dishes', 'disrespected', 'do', 'does', 'dog', 'dollars', 'don', 'done', 'dont', 'door', 'dos', 'doubt', 'douchey', 'doughy', 'down', 'downside', 'drag', 'dressed', 'dressing', 'dried', 'driest', 'drink', 'drinks', 'drive', 'driving', 'dry', 'duck', 'dude', 'during', 'dylan', 'each', 'easily', 'eat', 'eaten', 'eating', 'eclectic', 'editing', 'efficient', 'effort', 'egg', 'eggplant', 'either', 'elegantly', 'elk', 'else', 'elsewhere', 'employee', 'empty', 'ended', 'enjoy', 'enjoyable', 'enjoyed', 'enough', 'enthusiastic', 'entire', 'entrees', 'equally', 'especially', 'establishment', 'etc', 'ethic', 'eve', 'even', 'evening', 'event', 'events', 'ever', 'every', 'everything', 'everywhere', 'excellent', 'excuse', 'expanded', 'expect', 'expectations', 'expected', 'experience', 'experiencing', 'expert', 'exquisite', 'extensive', 'extra', 'extremely', 'fact', 'fail', 'fails', 'fair', 'falafels', 'family', 'famous', 'fan', 'fantastic', 'far', 'fast', 'fat', 'favorite', 'fear', 'feel', 'feeling', 'feels', 'fell', 'felt', 'few', 'fianc\\xc3\\xa9', 'figured', 'filet', 'finally', 'fine', 'finish', 'first', 'fish', 'flat', 'flavor', 'flavored', 'flavorful', 'flavorless', 'flirting', 'flower', 'fluffy', 'fly', 'fo', 'folks', 'food', 'foods', 'for', 'found', 'four', 'francisco', 'freaking', 'fresh', 'fridays', 'fried', 'friend', 'friendly', 'friends', 'fries', 'from', 'front', 'frozen', 'fruit', 'frustrated', 'fry', 'fs', 'full', 'fun', 'funny', 'fuzzy', 'ganoush', 'garden', 'garlic', 'gave', 'gc', 'generous', 'genuinely', 'get', 'gets', 'getting', 'give', 'given', 'glad', 'glance', 'glass', 'go', 'godfathers', 'going', 'gold', 'golden', 'gone', 'good', 'gooodd', 'got', 'gotten', 'gourmet', 'grain', 'gratitude', 'greasy', 'great', 'greek', 'green', 'greeted', 'grill', 'grilled', 'gringos', 'gristle', 'grocery', 'gross', 'grossed', 'ground', 'group', 'groups', 'grow', 'guess', 'guests', 'guy', 'had', 'hair', 'half', 'halibut', 'hand', 'handled', 'handmade', 'hands', 'happened', 'happy', 'hard', 'hardest', 'hardly', 'has', 'hate', 'have', 'haven', 'having', 'he', 'healthy', 'heart', 'heat', 'held', 'helpful', 'her', 'here', 'hereas', 'hi', 'high', 'highlights', 'highly', 'hilarious', 'him', 'hip', 'hiro', 'his', 'hit', 'holiday', 'home', 'homemade', 'honeslty', 'honest', 'honestly', 'honor', 'hopefully', 'hopes', 'horrible', 'host', 'hot', 'hottest', 'hour', 'hours', 'how', 'huge', 'human', 'hummus', 'hurry', 'husband', 'hut', 'i', 'ice', 'idea', 'if', 'ignore', 'im', 'imagination', 'imagined', 'immediately', 'impeccable', 'impressed', 'in', 'including', 'incredible', 'incredibly', 'indian', 'indoor', 'inexpensive', 'inflate', 'ingredients', 'inside', 'instead', 'insulted', 'interesting', 'into', 'inviting', 'ironman', 'is', 'isn', 'it', 'its', 'itself', 'japanese', 'jenni', 'jerk', 'job', 'joint', 'joke', 'judge', 'juice', 'just', 'kept', 'khao', 'kid', 'kiddos', 'kids', 'kind', 'kitchen', 'know', 'known', 'lack', 'lacked', 'lady', 'large', 'largely', 'last', 'late', 'later', 'law', 'lb', 'least', 'leather', 'leave', 'left', 'leftover', 'legs', 'lemon', 'let', 'letdown', 'letting', 'level', 'lighting', 'like', 'liked', 'liking', 'lil', 'limited', 'list', 'literally', 'little', 'live', 'll', 'lobster', 'located', 'long', 'look', 'looked', 'looking', 'looks', 'lordy', 'lost', 'lot', 'lots', 'loudly', 'love', 'loved', 'lovely', 'lovers', 'loves', 'low', 'lox', 'luke', 'lukewarm', 'lunch', 'm', 'mac', 'made', 'madison', 'mains', 'maintaining', 'make', 'making', 'mall', 'managed', 'management', 'manager', 'many', 'margaritas', 'maria', 'marrow', 'mary', 'massive', 'may', 'me', 'meal', 'meals', 'mean', 'meat', 'meatballs', 'meatloaf', 'mediocre', 'mediterranean', 'medium', 'meet', 'meh', 'melt', 'melted', 'mention', 'menu', 'metro', 'middle', 'min', 'mind', 'minutes', 'miss', 'missed', 'mistake', 'mixed', 'mmmm', 'modern', 'moist', 'mom', 'money', 'months', 'mood', 'more', 'mortified', 'mouth', 'mouthful', 'movies', 'moz', 'much', 'multi', 'multiple', 'mushrooms', 'music', 'must', 'my', 'naan', 'nachos', 'nasty', 'neat', 'need', 'needed', 'needless', 'needs', 'negligent', 'neither', 'never', 'new', 'next', 'nice', 'nicest', 'night', 'nigiri', 'no', 'nobu', 'noca', 'none', 'north', 'not', 'note', 'nothing', 'now', 'number', 'nut', 'nyc', 'obviously', 'occasional', 'occasions', 'of', 'off', 'offered', 'offers', 'officially', 'oh', 'ohhh', 'ok', 'old', 'olives', 'omelets', 'on', 'once', 'one', 'ones', 'only', 'opinion', 'opportunity', 'options', 'or', 'order', 'ordered', 'ordering', 'other', 'others', 'otherwise', 'our', 'out', 'outrageously', 'outshining', 'outside', 'outstanding', 'outta', 'oven', 'over', 'overall', 'overcooked', 'overpriced', 'overwhelmed', 'owned', 'owner', 'owners', 'oysters', 'pace', 'pack', 'packed', 'paid', 'pale', 'pancakes', 'papers', 'par', 'part', 'parties', 'party', 'passed', 'past', 'pasta', 'patio', 'pats', 'pay', 'paying', 'peach', 'peanut', 'peanuts', 'pears', 'pecan', 'people', 'pepper', 'perfect', 'perfectly', 'person', 'personable', 'personally', 'petty', 'philadelphia', 'pho', 'phoenix', 'piano', 'pictures', 'piece', 'pile', 'pine', 'pink', 'pita', 'pizza', 'pizzas', 'place', 'placed', 'places', 'plantains', 'plate', 'plater', 'platter', 'play', 'playing', 'pleasant', 'pleased', 'plethora', 'plus', 'point', 'poisoning', 'polite', 'poop', 'poor', 'poorly', 'pop', 'pork', 'portions', 'positive', 'possible', 'potato', 'potatoes', 'prefer', 'prepared', 'preparing', 'pretty', 'price', 'prices', 'pricey', 'prime', 'probably', 'problem', 'proclaimed', 'promise', 'prompt', 'proven', 'provided', 'provides', 'publicly', 'pulled', 'pumpkin', 'puree', 'quaint', 'qualified', 'quality', 'quick', 'quickly', 'quit', 'quite', 'rapidly', 'rare', 'rarely', 'raspberry', 'rate', 'rated', 'rather', 'ravoli', 're', 'real', 'realized', 'really', 'reasonable', 'reasons', 'received', 'receives', 'recent', 'recently', 'recommend', 'recommendation', 'recommended', 'red', 'redeeming', 'refill', 'refried', 'regular', 'reheated', 'relationship', 'relax', 'relaxed', 'remember', 'reminds', 'restaurant', 'restaurants', 'return', 'returned', 'review', 'reviewing', 'ri', 'rib', 'rice', 'rick', 'ridiculous', 'right', 'roast', 'roasted', 'rolls', 'room', 'rubber', 'rude', 'rudely', 'running', 's', 'sad', 'saffron', 'saganaki', 'said', 'salad', 'salads', 'salmon', 'salsa', 'same', 'san', 'sandwich', 'sandwiches', 'sangria', 'sashimi', 'satifying', 'satisfied', 'satisfying', 'sauce', 'saving', 'say', 'saying', 'says', 'scallop', 'scene', 'scottsdale', 'seafood', 'seal', 'seasonal', 'seasoned', 'seasoning', 'seated', 'seating', 'second', 'section', 'see', 'seemed', 'seems', 'seen', 'selection', 'selections', 'self', 'send', 'sergeant', 'seriously', 'serve', 'served', 'server', 'servers', 'service', 'services', 'set', 'setting', 'sever', 'several', 'sexy', 'shawarrrrrrma', 'she', 'shirt', 'shoe', 'shoots', 'shop', 'shopping', 'shops', 'should', 'show', 'showed', 'shrimp', 'sick', 'side', 'sides', 'similar', 'simple', 'since', 'single', 'sit', 'sitting', 'slow', 'small', 'smaller', 'smeared', 'so', 'soggy', 'soi', 'some', 'someone', 'something', 'soon', 'soooo', 'soooooo', 'sore', 'sorely', 'soundtrack', 'soup', 'soups', 'sour', 'southwest', 'space', 'spaghetti', 'special', 'speedy', 'spend', 'spends', 'spice', 'spicier', 'spicy', 'spinach', 'sporting', 'spot', 'spots', 'spotty', 'spring', 'staff', 'stale', 'star', 'stars', 'started', 'starving', 'station', 'steak', 'steaks', 'stepped', 'steve', 'still', 'stinks', 'stir', 'stopped', 'store', 'strange', 'strawberry', 'stretch', 'strings', 'strip', 'struck', 'struggle', 'stuff', 'stupid', 'style', 'styrofoam', 'sub', 'subpar', 'subway', 'such', 'sucked', 'sugary', 'suggest', 'summary', 'sunday', 'sunglasses', 'super', 'supposed', 'sure', 'surprise', 'sushi', 'sweet', 'swung', 't', 'table', 'tables', 'taco', 'tacos', 'take', 'talk', 'talking', 'tapas', 'tartar', 'taste', 'tasted', 'tasteless', 'tasty', 'tater', 'tea', 'teeth', 'tell', 'tender', 'tepid', 'terrible', 'texture', 'thai', 'than', 'thanks', 'that', 'the', 'theft', 'their', 'them', 'themselves', 'then', 'there', 'these', 'they', 'thin', 'thing', 'things', 'think', 'thinking', 'thirty', 'this', 'those', 'thought', 'three', 'ths', 'thumbs', 'thus', 'tigerlilly', 'time', 'times', 'tiny', 'tip', 'tiramisu', 'to', 'toasted', 'today', 'together', 'told', 'tolerance', 'tomato', 'tonight', 'too', 'took', 'top', 'topic', 'total', 'totally', 'tots', 'touch', 'towards', 'town', 'tracked', 'tragedy', 'treat', 'treated', 'tribute', 'tried', 'trimmed', 'trip', 'trippy', 'try', 'trying', 'tucson', 'tummy', 'tuna', 'turkey', 'tv', 'twice', 'two', 'typical', 'unbelievable', 'under', 'undercooked', 'underwhelming', 'unfortunately', 'unhealthy', 'uninspired', 'unless', 'until', 'unwelcome', 'up', 'us', 'used', 'usual', 'vacant', 'value', 've', 'vegan', 'vegas', 'vegetables', 'veggie', 'veggitarian', 'velvet', 'venue', 'verge', 'version', 'very', 'vibe', 'vinaigrette', 'visit', 'visited', 'waaaaaayyyyyyyyyy', 'wait', 'waited', 'waiter', 'waiting', 'waitress', 'waitresses', 'walked', 'wall', 'walls', 'want', 'wanted', 'warm', 'warmer', 'warnings', 'was', 'wash', 'wasn', 'waste', 'wasting', 'watch', 'watched', 'water', 'wave', 'way', 'wayyy', 'we', 'weak', 'wedges', 'week', 'weekend', 'weird', 'well', 'went', 'were', 'what', 'whatsoever', 'whelm', 'when', 'where', 'whether', 'which', 'while', 'white', 'who', 'why', 'wienerschnitzel', 'wife', 'wildly', 'will', 'wine', 'wines', 'wings', 'winner', 'wish', 'with', 'without', 'witnessed', 'won', 'wonderful', 'word', 'work', 'works', 'world', 'worse', 'worst', 'worth', 'would', 'wouldn', 'wow', 'wrap', 'wrapped', 'wrong', 'yama', 'yay', 'year', 'years', 'yellow', 'yet', 'you', 'your', 'yukon', 'yummy', 'zero']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = getVocab(trainingTokens)\n",
    "print(vocabulary)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
